* 
* ==> Audit <==
* |----------------|--------------------------------|----------|-------|---------|-------------------------------|-------------------------------|
|    Command     |              Args              | Profile  | User  | Version |          Start Time           |           End Time            |
|----------------|--------------------------------|----------|-------|---------|-------------------------------|-------------------------------|
| start          | --addons=dashboard             | minikube | mkong | v1.25.1 | Mon, 21 Feb 2022 08:48:24 CST | Mon, 21 Feb 2022 08:50:57 CST |
|                | --addons=metrics-server        |          |       |         |                               |                               |
|                | --addons=ingress               |          |       |         |                               |                               |
|                | --addons=ingress-dns           |          |       |         |                               |                               |
| stop           |                                | minikube | mkong | v1.25.1 | Mon, 21 Feb 2022 08:55:43 CST | Mon, 21 Feb 2022 08:55:55 CST |
| start          |                                | minikube | mkong | v1.25.1 | Mon, 21 Feb 2022 08:56:02 CST | Mon, 21 Feb 2022 08:57:51 CST |
| stop           |                                | minikube | mkong | v1.25.1 | Tue, 22 Feb 2022 15:42:18 CST | Tue, 22 Feb 2022 15:42:30 CST |
| start          |                                | minikube | mkong | v1.25.1 | Fri, 25 Feb 2022 10:10:38 CST | Fri, 25 Feb 2022 10:12:25 CST |
| addons         | list                           | minikube | mkong | v1.25.1 | Mon, 28 Feb 2022 13:32:23 CST | Mon, 28 Feb 2022 13:32:24 CST |
| stop           |                                | minikube | mkong | v1.25.1 | Thu, 03 Mar 2022 12:03:01 CST | Thu, 03 Mar 2022 12:03:14 CST |
| start          |                                | minikube | mkong | v1.25.1 | Thu, 03 Mar 2022 12:10:58 CST | Thu, 03 Mar 2022 12:12:46 CST |
| update-context |                                | minikube | mkong | v1.25.1 | Thu, 03 Mar 2022 16:11:54 CST | Thu, 03 Mar 2022 16:11:55 CST |
| config         | view                           | minikube | mkong | v1.25.1 | Thu, 03 Mar 2022 16:14:52 CST | Thu, 03 Mar 2022 16:14:52 CST |
| config         | view                           | minikube | mkong | v1.25.1 | Thu, 03 Mar 2022 16:15:03 CST | Thu, 03 Mar 2022 16:15:03 CST |
| stop           |                                | minikube | mkong | v1.25.1 | Thu, 03 Mar 2022 16:18:52 CST | Thu, 03 Mar 2022 16:19:03 CST |
| start          |                                | minikube | mkong | v1.25.1 | Thu, 03 Mar 2022 16:19:19 CST | Thu, 03 Mar 2022 16:20:29 CST |
| stop           |                                | minikube | mkong | v1.25.1 | Thu, 03 Mar 2022 16:24:03 CST | Thu, 03 Mar 2022 16:24:15 CST |
| start          |                                | minikube | mkong | v1.25.1 | Thu, 03 Mar 2022 16:27:51 CST | Thu, 03 Mar 2022 16:29:39 CST |
| service        | list                           | minikube | mkong | v1.25.1 | Thu, 03 Mar 2022 16:34:47 CST | Thu, 03 Mar 2022 16:34:49 CST |
| stop           |                                | minikube | mkong | v1.25.1 | Thu, 03 Mar 2022 21:03:57 CST | Thu, 03 Mar 2022 21:04:09 CST |
| start          |                                | minikube | mkong | v1.25.1 | Thu, 03 Mar 2022 21:12:06 CST | Thu, 03 Mar 2022 21:13:57 CST |
| stop           |                                | minikube | mkong | v1.25.1 | Mon, 07 Mar 2022 11:14:00 CST | Mon, 07 Mar 2022 11:14:14 CST |
| start          |                                | minikube | mkong | v1.25.1 | Mon, 07 Mar 2022 11:18:17 CST | Mon, 07 Mar 2022 11:20:06 CST |
| --help         |                                | minikube | mkong | v1.25.1 | Mon, 07 Mar 2022 11:46:49 CST | Mon, 07 Mar 2022 11:46:49 CST |
| stop           |                                | minikube | mkong | v1.25.1 | Fri, 11 Mar 2022 11:35:11 CST | Fri, 11 Mar 2022 11:35:27 CST |
| start          |                                | minikube | mkong | v1.25.1 | Fri, 11 Mar 2022 11:40:43 CST | Fri, 11 Mar 2022 11:42:35 CST |
| stop           |                                | minikube | mkong | v1.25.1 | Fri, 11 Mar 2022 12:11:16 CST | Fri, 11 Mar 2022 12:11:28 CST |
| stop           |                                | minikube | mkong | v1.25.1 | Fri, 11 Mar 2022 12:21:37 CST | Fri, 11 Mar 2022 12:21:49 CST |
| config         | view                           | minikube | mkong | v1.25.1 | Fri, 11 Mar 2022 12:25:05 CST | Fri, 11 Mar 2022 12:25:05 CST |
|----------------|--------------------------------|----------|-------|---------|-------------------------------|-------------------------------|

* 
* ==> Last Start <==
* Log file created at: 2022/03/11 12:30:55
Running on machine: mkong-mac
Binary: Built with gc go1.17.6 for darwin/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0311 12:30:55.914800   12354 out.go:297] Setting OutFile to fd 1 ...
I0311 12:30:55.915492   12354 out.go:325] MINIKUBE_IN_STYLE="false"
I0311 12:30:55.915495   12354 out.go:310] Setting ErrFile to fd 2...
I0311 12:30:55.915497   12354 out.go:325] MINIKUBE_IN_STYLE="false"
I0311 12:30:55.915583   12354 root.go:315] Updating PATH: /Users/mkong/.minikube/bin
W0311 12:30:55.916000   12354 root.go:293] Error reading config file at /Users/mkong/.minikube/config/config.json: open /Users/mkong/.minikube/config/config.json: no such file or directory
I0311 12:30:55.916567   12354 out.go:304] Setting JSON to false
I0311 12:30:55.976246   12354 start.go:112] hostinfo: {"hostname":"mkong-mac","uptime":3800401,"bootTime":1643223054,"procs":645,"os":"darwin","platform":"darwin","platformFamily":"Standalone Workstation","platformVersion":"11.6.1","kernelVersion":"20.6.0","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"d07231ba-aacc-5b6e-a767-9f1013958b56"}
W0311 12:30:55.976423   12354 start.go:120] gopshost.Virtualization returned error: not implemented yet
I0311 12:30:56.000855   12354 out.go:176] * minikube v1.25.1 on Darwin 11.6.1
I0311 12:30:56.003401   12354 notify.go:174] Checking for updates...
I0311 12:30:56.045043   12354 out.go:176]   - KUBECONFIG=/etc/kubernetes/admin.conf
I0311 12:30:56.068825   12354 out.go:176]   - MINIKUBE_HOME=
I0311 12:30:56.090863   12354 out.go:176]   - MINIKUBE_IN_STYLE=false
I0311 12:30:56.092918   12354 config.go:176] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.23.1
I0311 12:30:56.094739   12354 driver.go:344] Setting default libvirt URI to qemu:///system
I0311 12:30:56.436619   12354 docker.go:132] docker version: linux-20.10.10
I0311 12:30:56.437404   12354 cli_runner.go:133] Run: docker system info --format "{{json .}}"
I0311 12:30:57.021545   12354 info.go:263] docker info: {ID:GVU5:5VGG:6GD2:ZQ2M:XOKE:PZUD:AI4T:EKMU:YODN:L5J2:QRP6:H2R5 Containers:2 ContainersRunning:1 ContainersPaused:0 ContainersStopped:1 Images:11 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:56 OomKillDisable:true NGoroutines:50 SystemTime:2022-03-11 18:30:56.6027209 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:3 KernelVersion:5.10.47-linuxkit OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:6 MemTotal:2081755136 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy: Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.10 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:5b46e404f6b9f661a205e28d59c982d3634148f8 Expected:5b46e404f6b9f661a205e28d59c982d3634148f8} RuncCommit:{ID:v1.0.2-0-g52b36a2 Expected:v1.0.2-0-g52b36a2} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/local/lib/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Build with BuildKit Vendor:Docker Inc. Version:v0.6.3] map[Name:compose Path:/usr/local/lib/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.1.1] map[Name:scan Path:/usr/local/lib/docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:0.9.0]] Warnings:<nil>}}
I0311 12:30:57.064799   12354 out.go:176] * Using the docker driver based on existing profile
I0311 12:30:57.065253   12354 start.go:280] selected driver: docker
I0311 12:30:57.065259   12354 start.go:795] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.29@sha256:be897edc9ed473a9678010f390a0092f488f6a1c30865f571c3b6388f9f56f9b Memory:1985 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.23.1 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: ExtraOptions:[{Component:kubelet Key:housekeeping-interval Value:5m}] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.23.1 ControlPlane:true Worker:true}] Addons:map[ambassador:false auto-pause:false csi-hostpath-driver:false dashboard:true default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false helm-tiller:false ingress:true ingress-dns:true istio:false istio-provisioner:false kubevirt:false logviewer:false metallb:false metrics-server:true nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror:}
I0311 12:30:57.065336   12354 start.go:806] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc:}
I0311 12:30:57.065347   12354 start.go:1498] auto setting extra-config to "kubelet.housekeeping-interval=5m".
I0311 12:30:57.065528   12354 cli_runner.go:133] Run: docker system info --format "{{json .}}"
I0311 12:30:57.317660   12354 info.go:263] docker info: {ID:GVU5:5VGG:6GD2:ZQ2M:XOKE:PZUD:AI4T:EKMU:YODN:L5J2:QRP6:H2R5 Containers:2 ContainersRunning:1 ContainersPaused:0 ContainersStopped:1 Images:11 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:56 OomKillDisable:true NGoroutines:50 SystemTime:2022-03-11 18:30:57.2348943 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:3 KernelVersion:5.10.47-linuxkit OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:6 MemTotal:2081755136 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy: Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.10 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:5b46e404f6b9f661a205e28d59c982d3634148f8 Expected:5b46e404f6b9f661a205e28d59c982d3634148f8} RuncCommit:{ID:v1.0.2-0-g52b36a2 Expected:v1.0.2-0-g52b36a2} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/local/lib/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Build with BuildKit Vendor:Docker Inc. Version:v0.6.3] map[Name:compose Path:/usr/local/lib/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.1.1] map[Name:scan Path:/usr/local/lib/docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:0.9.0]] Warnings:<nil>}}
I0311 12:30:57.318009   12354 cni.go:93] Creating CNI manager for ""
I0311 12:30:57.318033   12354 cni.go:167] CNI unnecessary in this configuration, recommending no CNI
I0311 12:30:57.318039   12354 start_flags.go:300] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.29@sha256:be897edc9ed473a9678010f390a0092f488f6a1c30865f571c3b6388f9f56f9b Memory:1985 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.23.1 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: ExtraOptions:[{Component:kubelet Key:housekeeping-interval Value:5m}] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.23.1 ControlPlane:true Worker:true}] Addons:map[ambassador:false auto-pause:false csi-hostpath-driver:false dashboard:true default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false helm-tiller:false ingress:true ingress-dns:true istio:false istio-provisioner:false kubevirt:false logviewer:false metallb:false metrics-server:true nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror:}
I0311 12:30:57.339887   12354 out.go:176] * Starting control plane node minikube in cluster minikube
I0311 12:30:57.339976   12354 cache.go:120] Beginning downloading kic base image for docker with docker
I0311 12:30:57.383899   12354 out.go:176] * Pulling base image ...
I0311 12:30:57.384025   12354 preload.go:132] Checking if preload exists for k8s version v1.23.1 and runtime docker
I0311 12:30:57.384042   12354 image.go:75] Checking for gcr.io/k8s-minikube/kicbase:v0.0.29@sha256:be897edc9ed473a9678010f390a0092f488f6a1c30865f571c3b6388f9f56f9b in local docker daemon
I0311 12:30:57.384118   12354 preload.go:148] Found local preload: /Users/mkong/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v16-v1.23.1-docker-overlay2-amd64.tar.lz4
I0311 12:30:57.384145   12354 cache.go:57] Caching tarball of preloaded images
I0311 12:30:57.384908   12354 preload.go:174] Found /Users/mkong/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v16-v1.23.1-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0311 12:30:57.384963   12354 cache.go:60] Finished verifying existence of preloaded tar for  v1.23.1 on docker
I0311 12:30:57.386240   12354 profile.go:147] Saving config to /Users/mkong/.minikube/profiles/minikube/config.json ...
I0311 12:30:57.599007   12354 image.go:79] Found gcr.io/k8s-minikube/kicbase:v0.0.29@sha256:be897edc9ed473a9678010f390a0092f488f6a1c30865f571c3b6388f9f56f9b in local docker daemon, skipping pull
I0311 12:30:57.599023   12354 cache.go:142] gcr.io/k8s-minikube/kicbase:v0.0.29@sha256:be897edc9ed473a9678010f390a0092f488f6a1c30865f571c3b6388f9f56f9b exists in daemon, skipping load
I0311 12:30:57.599035   12354 cache.go:208] Successfully downloaded all kic artifacts
I0311 12:30:57.599089   12354 start.go:313] acquiring machines lock for minikube: {Name:mka3ebb9f11e1b7d92f0d306f6391f013356cd55 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0311 12:30:57.599367   12354 start.go:317] acquired machines lock for "minikube" in 248.138µs
I0311 12:30:57.599408   12354 start.go:93] Skipping create...Using existing machine configuration
I0311 12:30:57.599422   12354 fix.go:55] fixHost starting: 
I0311 12:30:57.599950   12354 cli_runner.go:133] Run: docker container inspect minikube --format={{.State.Status}}
I0311 12:30:57.787477   12354 fix.go:108] recreateIfNeeded on minikube: state=Running err=<nil>
W0311 12:30:57.787516   12354 fix.go:134] unexpected machine state, will restart: <nil>
I0311 12:30:57.810013   12354 out.go:176] * Updating the running docker "minikube" container ...
I0311 12:30:57.810088   12354 machine.go:88] provisioning docker machine ...
I0311 12:30:57.810673   12354 ubuntu.go:169] provisioning hostname "minikube"
I0311 12:30:57.811187   12354 cli_runner.go:133] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0311 12:30:58.006498   12354 main.go:130] libmachine: Using SSH client type: native
I0311 12:30:58.007492   12354 main.go:130] libmachine: &{{{<nil> 0 [] [] []} docker [0x439e7e0] 0x43a18c0 <nil>  [] 0s} 127.0.0.1 53551 <nil> <nil>}
I0311 12:30:58.007501   12354 main.go:130] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0311 12:30:58.201213   12354 main.go:130] libmachine: SSH cmd err, output: <nil>: minikube

I0311 12:30:58.201334   12354 cli_runner.go:133] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0311 12:30:58.381429   12354 main.go:130] libmachine: Using SSH client type: native
I0311 12:30:58.381742   12354 main.go:130] libmachine: &{{{<nil> 0 [] [] []} docker [0x439e7e0] 0x43a18c0 <nil>  [] 0s} 127.0.0.1 53551 <nil> <nil>}
I0311 12:30:58.381756   12354 main.go:130] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0311 12:30:58.530229   12354 main.go:130] libmachine: SSH cmd err, output: <nil>: 
I0311 12:30:58.530248   12354 ubuntu.go:175] set auth options {CertDir:/Users/mkong/.minikube CaCertPath:/Users/mkong/.minikube/certs/ca.pem CaPrivateKeyPath:/Users/mkong/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/Users/mkong/.minikube/machines/server.pem ServerKeyPath:/Users/mkong/.minikube/machines/server-key.pem ClientKeyPath:/Users/mkong/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/Users/mkong/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/Users/mkong/.minikube}
I0311 12:30:58.530279   12354 ubuntu.go:177] setting up certificates
I0311 12:30:58.530291   12354 provision.go:83] configureAuth start
I0311 12:30:58.530394   12354 cli_runner.go:133] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0311 12:30:58.729565   12354 provision.go:138] copyHostCerts
I0311 12:30:58.729899   12354 exec_runner.go:144] found /Users/mkong/.minikube/cert.pem, removing ...
I0311 12:30:58.729908   12354 exec_runner.go:207] rm: /Users/mkong/.minikube/cert.pem
I0311 12:30:58.730481   12354 exec_runner.go:151] cp: /Users/mkong/.minikube/certs/cert.pem --> /Users/mkong/.minikube/cert.pem (1119 bytes)
I0311 12:30:58.731246   12354 exec_runner.go:144] found /Users/mkong/.minikube/key.pem, removing ...
I0311 12:30:58.731250   12354 exec_runner.go:207] rm: /Users/mkong/.minikube/key.pem
I0311 12:30:58.731419   12354 exec_runner.go:151] cp: /Users/mkong/.minikube/certs/key.pem --> /Users/mkong/.minikube/key.pem (1675 bytes)
I0311 12:30:58.732107   12354 exec_runner.go:144] found /Users/mkong/.minikube/ca.pem, removing ...
I0311 12:30:58.732111   12354 exec_runner.go:207] rm: /Users/mkong/.minikube/ca.pem
I0311 12:30:58.732276   12354 exec_runner.go:151] cp: /Users/mkong/.minikube/certs/ca.pem --> /Users/mkong/.minikube/ca.pem (1074 bytes)
I0311 12:30:58.732648   12354 provision.go:112] generating server cert: /Users/mkong/.minikube/machines/server.pem ca-key=/Users/mkong/.minikube/certs/ca.pem private-key=/Users/mkong/.minikube/certs/ca-key.pem org=mkong.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0311 12:30:58.969787   12354 provision.go:172] copyRemoteCerts
I0311 12:30:58.970582   12354 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0311 12:30:58.970650   12354 cli_runner.go:133] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0311 12:30:59.167536   12354 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:53551 SSHKeyPath:/Users/mkong/.minikube/machines/minikube/id_rsa Username:docker}
I0311 12:30:59.275019   12354 ssh_runner.go:362] scp /Users/mkong/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1074 bytes)
I0311 12:30:59.302406   12354 ssh_runner.go:362] scp /Users/mkong/.minikube/machines/server.pem --> /etc/docker/server.pem (1196 bytes)
I0311 12:30:59.328450   12354 ssh_runner.go:362] scp /Users/mkong/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0311 12:30:59.356501   12354 provision.go:86] duration metric: configureAuth took 826.203803ms
I0311 12:30:59.356518   12354 ubuntu.go:193] setting minikube options for container-runtime
I0311 12:30:59.356834   12354 config.go:176] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.23.1
I0311 12:30:59.356913   12354 cli_runner.go:133] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0311 12:30:59.541328   12354 main.go:130] libmachine: Using SSH client type: native
I0311 12:30:59.541629   12354 main.go:130] libmachine: &{{{<nil> 0 [] [] []} docker [0x439e7e0] 0x43a18c0 <nil>  [] 0s} 127.0.0.1 53551 <nil> <nil>}
I0311 12:30:59.541638   12354 main.go:130] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0311 12:30:59.702012   12354 main.go:130] libmachine: SSH cmd err, output: <nil>: overlay

I0311 12:30:59.702025   12354 ubuntu.go:71] root file system type: overlay
I0311 12:30:59.702232   12354 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0311 12:30:59.702354   12354 cli_runner.go:133] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0311 12:30:59.894376   12354 main.go:130] libmachine: Using SSH client type: native
I0311 12:30:59.894693   12354 main.go:130] libmachine: &{{{<nil> 0 [] [] []} docker [0x439e7e0] 0x43a18c0 <nil>  [] 0s} 127.0.0.1 53551 <nil> <nil>}
I0311 12:30:59.894749   12354 main.go:130] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0311 12:31:00.066101   12354 main.go:130] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0311 12:31:00.066271   12354 cli_runner.go:133] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0311 12:31:00.257346   12354 main.go:130] libmachine: Using SSH client type: native
I0311 12:31:00.257654   12354 main.go:130] libmachine: &{{{<nil> 0 [] [] []} docker [0x439e7e0] 0x43a18c0 <nil>  [] 0s} 127.0.0.1 53551 <nil> <nil>}
I0311 12:31:00.257684   12354 main.go:130] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0311 12:31:00.420169   12354 main.go:130] libmachine: SSH cmd err, output: <nil>: 
I0311 12:31:00.420184   12354 machine.go:91] provisioned docker machine in 2.61011358s
I0311 12:31:00.420189   12354 start.go:267] post-start starting for "minikube" (driver="docker")
I0311 12:31:00.420193   12354 start.go:277] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0311 12:31:00.420293   12354 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0311 12:31:00.420347   12354 cli_runner.go:133] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0311 12:31:00.624773   12354 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:53551 SSHKeyPath:/Users/mkong/.minikube/machines/minikube/id_rsa Username:docker}
I0311 12:31:00.734129   12354 ssh_runner.go:195] Run: cat /etc/os-release
I0311 12:31:00.739873   12354 main.go:130] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0311 12:31:00.739891   12354 main.go:130] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0311 12:31:00.739898   12354 main.go:130] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0311 12:31:00.739904   12354 info.go:137] Remote host: Ubuntu 20.04.2 LTS
I0311 12:31:00.739922   12354 filesync.go:126] Scanning /Users/mkong/.minikube/addons for local assets ...
I0311 12:31:00.740329   12354 filesync.go:126] Scanning /Users/mkong/.minikube/files for local assets ...
I0311 12:31:00.740683   12354 start.go:270] post-start completed in 320.48632ms
I0311 12:31:00.740738   12354 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0311 12:31:00.740855   12354 cli_runner.go:133] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0311 12:31:00.928672   12354 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:53551 SSHKeyPath:/Users/mkong/.minikube/machines/minikube/id_rsa Username:docker}
I0311 12:31:01.032817   12354 fix.go:57] fixHost completed within 3.433427741s
I0311 12:31:01.032839   12354 start.go:80] releasing machines lock for "minikube", held for 3.433485505s
I0311 12:31:01.032961   12354 cli_runner.go:133] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0311 12:31:01.226655   12354 ssh_runner.go:195] Run: systemctl --version
I0311 12:31:01.226763   12354 cli_runner.go:133] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0311 12:31:01.228011   12354 ssh_runner.go:195] Run: curl -sS -m 2 https://k8s.gcr.io/
I0311 12:31:01.228453   12354 cli_runner.go:133] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0311 12:31:01.439470   12354 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:53551 SSHKeyPath:/Users/mkong/.minikube/machines/minikube/id_rsa Username:docker}
I0311 12:31:01.452079   12354 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:53551 SSHKeyPath:/Users/mkong/.minikube/machines/minikube/id_rsa Username:docker}
I0311 12:31:01.540102   12354 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I0311 12:31:01.954492   12354 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0311 12:31:01.973270   12354 cruntime.go:272] skipping containerd shutdown because we are bound to it
I0311 12:31:01.973363   12354 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0311 12:31:01.990644   12354 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/dockershim.sock
image-endpoint: unix:///var/run/dockershim.sock
" | sudo tee /etc/crictl.yaml"
I0311 12:31:02.013482   12354 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0311 12:31:02.126317   12354 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0311 12:31:02.268485   12354 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0311 12:31:02.285209   12354 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0311 12:31:02.394887   12354 ssh_runner.go:195] Run: sudo systemctl start docker
I0311 12:31:02.411005   12354 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0311 12:31:02.491061   12354 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0311 12:31:02.587567   12354 out.go:203] * Preparing Kubernetes v1.23.1 on Docker 20.10.12 ...
I0311 12:31:02.587700   12354 cli_runner.go:133] Run: docker exec -t minikube dig +short host.docker.internal
I0311 12:31:02.899132   12354 network.go:96] got host ip for mount in container by digging dns: 192.168.65.2
I0311 12:31:02.899306   12354 ssh_runner.go:195] Run: grep 192.168.65.2	host.minikube.internal$ /etc/hosts
I0311 12:31:02.906555   12354 cli_runner.go:133] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0311 12:31:03.097589   12354 out.go:176]   - kubelet.housekeeping-interval=5m
I0311 12:31:03.097718   12354 preload.go:132] Checking if preload exists for k8s version v1.23.1 and runtime docker
I0311 12:31:03.097797   12354 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0311 12:31:03.141635   12354 docker.go:606] Got preloaded images: -- stdout --
nginx:latest
k8s.gcr.io/kube-apiserver:v1.23.1
k8s.gcr.io/kube-proxy:v1.23.1
k8s.gcr.io/kube-controller-manager:v1.23.1
k8s.gcr.io/kube-scheduler:v1.23.1
k8s.gcr.io/ingress-nginx/controller:<none>
k8s.gcr.io/etcd:3.5.1-0
gcr.io/k8s-minikube/minikube-ingress-dns:<none>
k8s.gcr.io/ingress-nginx/kube-webhook-certgen:<none>
k8s.gcr.io/coredns/coredns:v1.8.6
k8s.gcr.io/pause:3.6
kubernetesui/dashboard:v2.3.1
kubernetesui/metrics-scraper:v1.0.7
gcr.io/k8s-minikube/storage-provisioner:v5
k8s.gcr.io/metrics-server/metrics-server:<none>
postgres:9.6.5

-- /stdout --
I0311 12:31:03.142076   12354 docker.go:537] Images already preloaded, skipping extraction
I0311 12:31:03.142414   12354 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0311 12:31:03.181538   12354 docker.go:606] Got preloaded images: -- stdout --
nginx:latest
k8s.gcr.io/kube-apiserver:v1.23.1
k8s.gcr.io/kube-proxy:v1.23.1
k8s.gcr.io/kube-controller-manager:v1.23.1
k8s.gcr.io/kube-scheduler:v1.23.1
k8s.gcr.io/ingress-nginx/controller:<none>
k8s.gcr.io/etcd:3.5.1-0
gcr.io/k8s-minikube/minikube-ingress-dns:<none>
k8s.gcr.io/ingress-nginx/kube-webhook-certgen:<none>
k8s.gcr.io/coredns/coredns:v1.8.6
k8s.gcr.io/pause:3.6
kubernetesui/dashboard:v2.3.1
kubernetesui/metrics-scraper:v1.0.7
gcr.io/k8s-minikube/storage-provisioner:v5
k8s.gcr.io/metrics-server/metrics-server:<none>
postgres:9.6.5

-- /stdout --
I0311 12:31:03.181553   12354 cache_images.go:84] Images are preloaded, skipping loading
I0311 12:31:03.181644   12354 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0311 12:31:03.286256   12354 cni.go:93] Creating CNI manager for ""
I0311 12:31:03.286265   12354 cni.go:167] CNI unnecessary in this configuration, recommending no CNI
I0311 12:31:03.286280   12354 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0311 12:31:03.286294   12354 kubeadm.go:153] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.23.1 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/dockershim.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NoTaintMaster:true NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[]}
I0311 12:31:03.286450   12354 kubeadm.go:157] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta2
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.23.1
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0311 12:31:03.286549   12354 kubeadm.go:791] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.23.1/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime=docker --hostname-override=minikube --housekeeping-interval=5m --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.23.1 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: ExtraOptions:[{Component:kubelet Key:housekeeping-interval Value:5m}] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0311 12:31:03.286638   12354 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.23.1
I0311 12:31:03.296049   12354 binaries.go:44] Found k8s binaries, skipping transfer
I0311 12:31:03.296128   12354 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0311 12:31:03.304762   12354 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (361 bytes)
I0311 12:31:03.320110   12354 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0311 12:31:03.340378   12354 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2051 bytes)
I0311 12:31:03.366381   12354 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0311 12:31:03.377695   12354 certs.go:54] Setting up /Users/mkong/.minikube/profiles/minikube for IP: 192.168.49.2
I0311 12:31:03.379263   12354 certs.go:182] skipping minikubeCA CA generation: /Users/mkong/.minikube/ca.key
I0311 12:31:03.379971   12354 certs.go:182] skipping proxyClientCA CA generation: /Users/mkong/.minikube/proxy-client-ca.key
I0311 12:31:03.381465   12354 certs.go:298] skipping minikube-user signed cert generation: /Users/mkong/.minikube/profiles/minikube/client.key
I0311 12:31:03.382281   12354 certs.go:298] skipping minikube signed cert generation: /Users/mkong/.minikube/profiles/minikube/apiserver.key.dd3b5fb2
I0311 12:31:03.382976   12354 certs.go:298] skipping aggregator signed cert generation: /Users/mkong/.minikube/profiles/minikube/proxy-client.key
I0311 12:31:03.384628   12354 certs.go:388] found cert: /Users/mkong/.minikube/certs/Users/mkong/.minikube/certs/ca-key.pem (1679 bytes)
I0311 12:31:03.384819   12354 certs.go:388] found cert: /Users/mkong/.minikube/certs/Users/mkong/.minikube/certs/ca.pem (1074 bytes)
I0311 12:31:03.384961   12354 certs.go:388] found cert: /Users/mkong/.minikube/certs/Users/mkong/.minikube/certs/cert.pem (1119 bytes)
I0311 12:31:03.385141   12354 certs.go:388] found cert: /Users/mkong/.minikube/certs/Users/mkong/.minikube/certs/key.pem (1675 bytes)
I0311 12:31:03.387352   12354 ssh_runner.go:362] scp /Users/mkong/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0311 12:31:03.431539   12354 ssh_runner.go:362] scp /Users/mkong/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0311 12:31:03.473453   12354 ssh_runner.go:362] scp /Users/mkong/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0311 12:31:03.511916   12354 ssh_runner.go:362] scp /Users/mkong/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1675 bytes)
I0311 12:31:03.551594   12354 ssh_runner.go:362] scp /Users/mkong/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0311 12:31:03.613571   12354 ssh_runner.go:362] scp /Users/mkong/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0311 12:31:03.660064   12354 ssh_runner.go:362] scp /Users/mkong/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0311 12:31:03.694714   12354 ssh_runner.go:362] scp /Users/mkong/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I0311 12:31:03.734042   12354 ssh_runner.go:362] scp /Users/mkong/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0311 12:31:03.772514   12354 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0311 12:31:03.795860   12354 ssh_runner.go:195] Run: openssl version
I0311 12:31:03.803949   12354 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0311 12:31:03.819054   12354 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0311 12:31:03.826418   12354 certs.go:431] hashing: -rw-r--r-- 1 root root 1111 Feb 21 14:49 /usr/share/ca-certificates/minikubeCA.pem
I0311 12:31:03.826498   12354 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0311 12:31:03.834802   12354 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0311 12:31:03.847009   12354 kubeadm.go:388] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.29@sha256:be897edc9ed473a9678010f390a0092f488f6a1c30865f571c3b6388f9f56f9b Memory:1985 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.23.1 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: ExtraOptions:[{Component:kubelet Key:housekeeping-interval Value:5m}] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.23.1 ControlPlane:true Worker:true}] Addons:map[ambassador:false auto-pause:false csi-hostpath-driver:false dashboard:true default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false helm-tiller:false ingress:true ingress-dns:true istio:false istio-provisioner:false kubevirt:false logviewer:false metallb:false metrics-server:true nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror:}
I0311 12:31:03.847174   12354 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0311 12:31:03.894178   12354 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0311 12:31:03.905910   12354 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0311 12:31:03.917367   12354 kubeadm.go:124] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0311 12:31:03.917451   12354 cli_runner.go:133] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0311 12:31:04.166425   12354 kubeconfig.go:116] verify returned: extract IP: "minikube" does not appear in /etc/kubernetes/admin.conf
I0311 12:31:04.166477   12354 kubeconfig.go:127] "minikube" context is missing from /etc/kubernetes/admin.conf - will repair!
W0311 12:31:04.167096   12354 kubeadm.go:581] unable to update kubeconfig (cluster will likely require a reset): write: Error creating directory: /etc/kubernetes: mkdir /etc/kubernetes: permission denied
W0311 12:31:04.167527   12354 loader.go:221] Config not found: /etc/kubernetes/admin.conf
W0311 12:31:04.167578   12354 kubeadm.go:586] needs reconfigure: getting k8s client error: client config: client config: context "minikube" does not exist
I0311 12:31:04.167604   12354 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.23.1:$PATH" kubeadm reset --cri-socket /var/run/dockershim.sock --force"
I0311 12:31:36.893762   12354 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.23.1:$PATH" kubeadm reset --cri-socket /var/run/dockershim.sock --force": (32.726419749s)
I0311 12:31:36.893857   12354 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0311 12:31:36.905820   12354 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0311 12:31:36.914909   12354 kubeadm.go:218] ignoring SystemVerification for kubeadm because of docker driver
I0311 12:31:36.914979   12354 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0311 12:31:36.924109   12354 kubeadm.go:149] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0311 12:31:36.924142   12354 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.23.1:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables"
I0311 12:31:37.545148   12354 out.go:203]   - Generating certificates and keys ...
I0311 12:31:38.451723   12354 out.go:203]   - Booting up control plane ...
I0311 12:31:48.032118   12354 out.go:203]   - Configuring RBAC rules ...
I0311 12:31:48.455681   12354 cni.go:93] Creating CNI manager for ""
I0311 12:31:48.455691   12354 cni.go:167] CNI unnecessary in this configuration, recommending no CNI
I0311 12:31:48.455725   12354 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0311 12:31:48.455875   12354 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.23.1/kubectl label nodes minikube.k8s.io/version=v1.25.1 minikube.k8s.io/commit=3e64b11ed75e56e4898ea85f96b2e4af0301f43d minikube.k8s.io/name=minikube minikube.k8s.io/updated_at=2022_03_11T12_31_48_0700 --all --overwrite --kubeconfig=/var/lib/minikube/kubeconfig
I0311 12:31:48.455885   12354 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.23.1/kubectl create clusterrolebinding minikube-rbac --clusterrole=cluster-admin --serviceaccount=kube-system:default --kubeconfig=/var/lib/minikube/kubeconfig
I0311 12:31:48.674387   12354 kubeadm.go:867] duration metric: took 218.623928ms to wait for elevateKubeSystemPrivileges.
I0311 12:31:48.674436   12354 ops.go:34] apiserver oom_adj: -16
I0311 12:31:48.674458   12354 kubeadm.go:390] StartCluster complete in 44.827828903s
I0311 12:31:48.674474   12354 settings.go:142] acquiring lock: {Name:mkd828db7b7cf864e2d4d124744c6ee9c2490d8b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0311 12:31:48.674877   12354 settings.go:150] Updating kubeconfig:  /etc/kubernetes/admin.conf
I0311 12:31:48.715085   12354 out.go:176] 
W0311 12:31:48.715218   12354 out.go:241] X Exiting due to GUEST_START: Failed kubeconfig update: writing kubeconfig: Error creating directory: /etc/kubernetes: mkdir /etc/kubernetes: permission denied
W0311 12:31:48.715229   12354 out.go:241] * 
W0311 12:31:48.715954   12354 out.go:241] ╭─────────────────────────────────────────────────────────────────────────────────────────────╮
│                                                                                             │
│    * If the above advice does not help, please let us know:                                 │
│      https://github.com/kubernetes/minikube/issues/new/choose                               │
│                                                                                             │
│    * Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    │
│                                                                                             │
╰─────────────────────────────────────────────────────────────────────────────────────────────╯

* 
* ==> Docker <==
* -- Logs begin at Fri 2022-03-11 18:28:05 UTC, end at Fri 2022-03-11 18:32:12 UTC. --
Mar 11 18:28:05 minikube systemd[1]: Starting Docker Application Container Engine...
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.213843200Z" level=info msg="Starting up"
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.216635300Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.216690900Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.216728200Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.216759800Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.218801900Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.218850400Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.218879600Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.218903500Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.228629300Z" level=info msg="[graphdriver] using prior storage driver: overlay2"
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.308824600Z" level=warning msg="Your kernel does not support cgroup blkio weight"
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.308875000Z" level=warning msg="Your kernel does not support cgroup blkio weight_device"
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.309138900Z" level=info msg="Loading containers: start."
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.452095200Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.506998800Z" level=info msg="Loading containers: done."
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.527467900Z" level=info msg="Docker daemon" commit=459d0df graphdriver(s)=overlay2 version=20.10.12
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.527587300Z" level=info msg="Daemon has completed initialization"
Mar 11 18:28:05 minikube systemd[1]: Started Docker Application Container Engine.
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.570139200Z" level=info msg="API listen on [::]:2376"
Mar 11 18:28:05 minikube dockerd[216]: time="2022-03-11T18:28:05.577154300Z" level=info msg="API listen on /var/run/docker.sock"
Mar 11 18:31:09 minikube dockerd[216]: time="2022-03-11T18:31:09.828910100Z" level=info msg="ignoring event" container=66a1f703f0d9ec610198fd5f6feb30b31dd18c2ca7fc87cbb5235084d36e8c9a module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 11 18:31:14 minikube dockerd[216]: time="2022-03-11T18:31:14.947929400Z" level=info msg="ignoring event" container=5059de61dd0ac4a28f00c740f5d247ff3dbcfa9e33ff2bbfc8d01c38bb941acc module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 11 18:31:15 minikube dockerd[216]: time="2022-03-11T18:31:15.109334300Z" level=info msg="ignoring event" container=2b5c0533d9f73532a7a59ddf953396a77bf908d8bff88be0c424b0c548cc6c87 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 11 18:31:15 minikube dockerd[216]: time="2022-03-11T18:31:15.302127800Z" level=info msg="ignoring event" container=263f583c4cd33f20250caae28c9c575e95f9c7991de3aa8290c155e946bc8545 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 11 18:31:15 minikube dockerd[216]: time="2022-03-11T18:31:15.496761200Z" level=info msg="ignoring event" container=2e4bdab5e1f2edd3b070f04dcb66400aefa4d692858e86a9ebd8ccc15fda9335 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 11 18:31:15 minikube dockerd[216]: time="2022-03-11T18:31:15.629024400Z" level=info msg="ignoring event" container=1fd4f3a1a5386bd4073ae32ce9074674bd2b017f85543cbc53b9e7c3dd9dbfd9 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 11 18:31:15 minikube dockerd[216]: time="2022-03-11T18:31:15.779321500Z" level=info msg="ignoring event" container=d56d4f1d12cf0bf756984a31d18573e64cd12260a6edc2c01cfa5a04c5618185 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 11 18:31:25 minikube dockerd[216]: time="2022-03-11T18:31:25.934161000Z" level=info msg="Container failed to exit within 10s of signal 15 - using the force" container=85d1188241e219812057a18124b52023866584b509748ff05c4b085b911796b6
Mar 11 18:31:26 minikube dockerd[216]: time="2022-03-11T18:31:26.013494100Z" level=info msg="ignoring event" container=85d1188241e219812057a18124b52023866584b509748ff05c4b085b911796b6 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 11 18:31:26 minikube dockerd[216]: time="2022-03-11T18:31:26.167065700Z" level=info msg="ignoring event" container=9b761ffe1bc69f73570465a7af1c1563248d52ce5abb7e9e62529c74f466f1e2 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 11 18:31:36 minikube dockerd[216]: time="2022-03-11T18:31:36.281755900Z" level=info msg="Container failed to exit within 10s of signal 15 - using the force" container=196c1902eefeb283a87d45c562731295740d3c02a0024cab7c2e691f35676002
Mar 11 18:31:36 minikube dockerd[216]: time="2022-03-11T18:31:36.335096800Z" level=info msg="ignoring event" container=196c1902eefeb283a87d45c562731295740d3c02a0024cab7c2e691f35676002 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 11 18:31:36 minikube dockerd[216]: time="2022-03-11T18:31:36.456527700Z" level=info msg="ignoring event" container=6047a0a8579c225f8a4ddd88558ff13bda5f18c6858301b94fe8dc038b01bb82 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 11 18:31:36 minikube dockerd[216]: time="2022-03-11T18:31:36.588152200Z" level=info msg="ignoring event" container=0005d4ffa233dff55ad2755287e7e89d3232bedd78235da8d141e629b3ba439c module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 11 18:31:36 minikube dockerd[216]: time="2022-03-11T18:31:36.725180000Z" level=info msg="ignoring event" container=63dd97649f02d44b8489bdbb940dd20b08a84636a187100fda34c1862a9356fd module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Mar 11 18:31:36 minikube dockerd[216]: time="2022-03-11T18:31:36.852461500Z" level=info msg="ignoring event" container=3687313ecf10b0ccc954c9af62fad1652fbaa9c3c1f190f469644349a39e533d module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"

* 
* ==> container status <==
* CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID
519aad5b0290d       a4ca41631cc7a       10 seconds ago      Running             coredns                   0                   69b427ea64e4c
e4d5ecc37351b       a4ca41631cc7a       10 seconds ago      Running             coredns                   0                   f72c38b9191e4
5e7f097ddd9d3       b46c42588d511       10 seconds ago      Running             kube-proxy                0                   bfd1f06e91add
acb3d74309a1a       f51846a4fd288       32 seconds ago      Running             kube-controller-manager   14                  5ee9c8358bc4e
569c8bac25c05       b6d7abedde399       32 seconds ago      Running             kube-apiserver            14                  a66ca75f08ccf
211171ece575c       25f8c7f3da61c       32 seconds ago      Running             etcd                      14                  e9408c58854e0
f0562a22e7dc8       71d575efe6283       32 seconds ago      Running             kube-scheduler            14                  fa0ddc825b554

* 
* ==> coredns [519aad5b0290] <==
* .:53
[INFO] plugin/reload: Running configuration MD5 = db32ca3650231d74073ff4cf814959a7
CoreDNS-1.8.6
linux/amd64, go1.17.1, 13a9191

* 
* ==> coredns [e4d5ecc37351] <==
* .:53
[INFO] plugin/reload: Running configuration MD5 = db32ca3650231d74073ff4cf814959a7
CoreDNS-1.8.6
linux/amd64, go1.17.1, 13a9191

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane,master
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=3e64b11ed75e56e4898ea85f96b2e4af0301f43d
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/updated_at=2022_03_11T12_31_48_0700
                    minikube.k8s.io/version=v1.25.1
                    node-role.kubernetes.io/control-plane=
                    node-role.kubernetes.io/master=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Fri, 11 Mar 2022 18:31:44 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Fri, 11 Mar 2022 18:32:09 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Fri, 11 Mar 2022 18:31:59 +0000   Fri, 11 Mar 2022 18:31:42 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Fri, 11 Mar 2022 18:31:59 +0000   Fri, 11 Mar 2022 18:31:42 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Fri, 11 Mar 2022 18:31:59 +0000   Fri, 11 Mar 2022 18:31:42 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Fri, 11 Mar 2022 18:31:59 +0000   Fri, 11 Mar 2022 18:31:59 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                6
  ephemeral-storage:  61255492Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             2032964Ki
  pods:               110
Allocatable:
  cpu:                6
  ephemeral-storage:  61255492Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             2032964Ki
  pods:               110
System Info:
  Machine ID:                 8de776e053e140d6a14c2d2def3d6bb8
  System UUID:                fe13a49f-0e22-4536-8ac1-989a475fecf5
  Boot ID:                    bbf382f7-186f-425b-b1ae-d33e15db9b88
  Kernel Version:             5.10.47-linuxkit
  OS Image:                   Ubuntu 20.04.2 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://20.10.12
  Kubelet Version:            v1.23.1
  Kube-Proxy Version:         v1.23.1
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (7 in total)
  Namespace                   Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                ------------  ----------  ---------------  -------------  ---
  kube-system                 coredns-64897985d-cm25d             100m (1%!)(MISSING)     0 (0%!)(MISSING)      70Mi (3%!)(MISSING)        170Mi (8%!)(MISSING)     12s
  kube-system                 coredns-64897985d-hbkln             100m (1%!)(MISSING)     0 (0%!)(MISSING)      70Mi (3%!)(MISSING)        170Mi (8%!)(MISSING)     12s
  kube-system                 etcd-minikube                       100m (1%!)(MISSING)     0 (0%!)(MISSING)      100Mi (5%!)(MISSING)       0 (0%!)(MISSING)         27s
  kube-system                 kube-apiserver-minikube             250m (4%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         27s
  kube-system                 kube-controller-manager-minikube    200m (3%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         24s
  kube-system                 kube-proxy-nnr47                    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         12s
  kube-system                 kube-scheduler-minikube             100m (1%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         27s
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests     Limits
  --------           --------     ------
  cpu                850m (14%!)(MISSING)   0 (0%!)(MISSING)
  memory             240Mi (12%!)(MISSING)  340Mi (17%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)       0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)       0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)       0 (0%!)(MISSING)
Events:
  Type    Reason                   Age                From        Message
  ----    ------                   ----               ----        -------
  Normal  Starting                 10s                kube-proxy  
  Normal  NodeHasSufficientMemory  34s (x4 over 34s)  kubelet     Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    34s (x4 over 34s)  kubelet     Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     34s (x4 over 34s)  kubelet     Node minikube status is now: NodeHasSufficientPID
  Normal  NodeAllocatableEnforced  34s                kubelet     Updated Node Allocatable limit across pods
  Normal  Starting                 25s                kubelet     Starting kubelet.
  Normal  NodeHasNoDiskPressure    25s                kubelet     Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     25s                kubelet     Node minikube status is now: NodeHasSufficientPID
  Normal  NodeHasSufficientMemory  25s                kubelet     Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeNotReady             24s                kubelet     Node minikube status is now: NodeNotReady
  Normal  NodeAllocatableEnforced  24s                kubelet     Updated Node Allocatable limit across pods
  Normal  NodeReady                14s                kubelet     Node minikube status is now: NodeReady

* 
* ==> dmesg <==
* [Feb23 18:29] ERROR: earlyprintk= earlyser already used
[  +0.000000] ERROR: earlyprintk= earlyser already used
[  +0.000000] ACPI BIOS Warning (bug): Incorrect checksum in table [DSDT] - 0x7E, should be 0xDB (20200925/tbprint-173)
[  +0.211664]  #2
[  +0.063996]  #3
[  +0.064002]  #4
[  +0.070116]  #5
[  +2.687393] Hangcheck: starting hangcheck timer 0.9.1 (tick is 180 seconds, margin is 60 seconds).
[  +0.050219] ACPI Error: Could not enable RealTimeClock event (20200925/evxfevnt-182)
[  +0.003360] ACPI Warning: Could not enable fixed event - RealTimeClock (4) (20200925/evxface-618)
[  +4.703540] grpcfuse: loading out-of-tree module taints kernel.
[Feb23 22:24] clocksource: timekeeping watchdog on CPU5: Marking clocksource 'tsc' as unstable because the skew is too large:
[  +0.006800] clocksource:                       'hpet' wd_now: e6eb4afb wd_last: e6200ed3 mask: ffffffff
[  +0.004094] clocksource:                       'tsc' cs_now: 524eca4cf702 cs_last: 524e078bfb54 mask: ffffffffffffffff
[  +0.008908] TSC found unstable after boot, most likely due to broken BIOS. Use 'tsc=unstable'.
[Feb23 22:30] hrtimer: interrupt took 2877400 ns

* 
* ==> etcd [211171ece575] <==
* {"level":"info","ts":"2022-03-11T18:31:40.617Z","caller":"etcdmain/etcd.go:72","msg":"Running: ","args":["etcd","--advertise-client-urls=https://192.168.49.2:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--initial-advertise-peer-urls=https://192.168.49.2:2380","--initial-cluster=minikube=https://192.168.49.2:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://192.168.49.2:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"info","ts":"2022-03-11T18:31:40.617Z","caller":"embed/etcd.go:131","msg":"configuring peer listeners","listen-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2022-03-11T18:31:40.617Z","caller":"embed/etcd.go:478","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2022-03-11T18:31:40.617Z","caller":"embed/etcd.go:139","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"]}
{"level":"info","ts":"2022-03-11T18:31:40.617Z","caller":"embed/etcd.go:307","msg":"starting an etcd server","etcd-version":"3.5.1","git-sha":"e8732fb5f","go-version":"go1.16.3","go-os":"linux","go-arch":"amd64","max-cpu-set":6,"max-cpu-available":6,"member-initialized":false,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"minikube=https://192.168.49.2:2380","initial-cluster-state":"new","initial-cluster-token":"etcd-cluster","quota-size-bytes":2147483648,"pre-vote":true,"initial-corrupt-check":false,"corrupt-check-time-interval":"0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2022-03-11T18:31:40.620Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"1.972ms"}
{"level":"info","ts":"2022-03-11T18:31:40.625Z","caller":"etcdserver/raft.go:448","msg":"starting local member","local-member-id":"aec36adc501070cc","cluster-id":"fa54960ea34d58be"}
{"level":"info","ts":"2022-03-11T18:31:40.625Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=()"}
{"level":"info","ts":"2022-03-11T18:31:40.625Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 0"}
{"level":"info","ts":"2022-03-11T18:31:40.625Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft aec36adc501070cc [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]"}
{"level":"info","ts":"2022-03-11T18:31:40.625Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 1"}
{"level":"info","ts":"2022-03-11T18:31:40.625Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"warn","ts":"2022-03-11T18:31:40.682Z","caller":"auth/store.go:1220","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2022-03-11T18:31:40.685Z","caller":"mvcc/kvstore.go:415","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2022-03-11T18:31:40.687Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2022-03-11T18:31:40.689Z","caller":"etcdserver/server.go:843","msg":"starting etcd server","local-member-id":"aec36adc501070cc","local-server-version":"3.5.1","cluster-version":"to_be_decided"}
{"level":"info","ts":"2022-03-11T18:31:40.689Z","caller":"etcdserver/server.go:728","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"aec36adc501070cc","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2022-03-11T18:31:40.691Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"info","ts":"2022-03-11T18:31:40.691Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","added-peer-id":"aec36adc501070cc","added-peer-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2022-03-11T18:31:40.696Z","caller":"embed/etcd.go:687","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2022-03-11T18:31:40.696Z","caller":"embed/etcd.go:580","msg":"serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2022-03-11T18:31:40.696Z","caller":"embed/etcd.go:552","msg":"cmux::serve","address":"192.168.49.2:2380"}
{"level":"info","ts":"2022-03-11T18:31:40.696Z","caller":"embed/etcd.go:276","msg":"now serving peer/client/metrics","local-member-id":"aec36adc501070cc","initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2022-03-11T18:31:40.696Z","caller":"embed/etcd.go:762","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2022-03-11T18:31:41.679Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc is starting a new election at term 1"}
{"level":"info","ts":"2022-03-11T18:31:41.680Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became pre-candidate at term 1"}
{"level":"info","ts":"2022-03-11T18:31:41.680Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgPreVoteResp from aec36adc501070cc at term 1"}
{"level":"info","ts":"2022-03-11T18:31:41.680Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became candidate at term 2"}
{"level":"info","ts":"2022-03-11T18:31:41.680Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgVoteResp from aec36adc501070cc at term 2"}
{"level":"info","ts":"2022-03-11T18:31:41.680Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became leader at term 2"}
{"level":"info","ts":"2022-03-11T18:31:41.680Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: aec36adc501070cc elected leader aec36adc501070cc at term 2"}
{"level":"info","ts":"2022-03-11T18:31:41.680Z","caller":"etcdserver/server.go:2476","msg":"setting up initial cluster version using v2 API","cluster-version":"3.5"}
{"level":"info","ts":"2022-03-11T18:31:41.683Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","cluster-version":"3.5"}
{"level":"info","ts":"2022-03-11T18:31:41.683Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2022-03-11T18:31:41.683Z","caller":"etcdserver/server.go:2500","msg":"cluster version is updated","cluster-version":"3.5"}
{"level":"info","ts":"2022-03-11T18:31:41.683Z","caller":"etcdserver/server.go:2027","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2022-03-11T18:31:41.683Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2022-03-11T18:31:41.684Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2022-03-11T18:31:41.650Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"info","ts":"2022-03-11T18:31:41.652Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"192.168.49.2:2379"}
{"level":"info","ts":"2022-03-11T18:31:41.652Z","caller":"etcdmain/main.go:47","msg":"notifying init daemon"}
{"level":"info","ts":"2022-03-11T18:31:41.653Z","caller":"etcdmain/main.go:53","msg":"successfully notified init daemon"}

* 
* ==> kernel <==
*  18:32:13 up 16 days, 2 min,  0 users,  load average: 0.42, 0.25, 0.27
Linux minikube 5.10.47-linuxkit #1 SMP Sat Jul 3 21:51:47 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 20.04.2 LTS"

* 
* ==> kube-apiserver [569c8bac25c0] <==
* W0311 18:31:43.334846       1 genericapiserver.go:538] Skipping API apps/v1beta2 because it has no resources.
W0311 18:31:43.334893       1 genericapiserver.go:538] Skipping API apps/v1beta1 because it has no resources.
W0311 18:31:43.337535       1 genericapiserver.go:538] Skipping API admissionregistration.k8s.io/v1beta1 because it has no resources.
I0311 18:31:43.341247       1 plugins.go:158] Loaded 12 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionWebhook.
I0311 18:31:43.341284       1 plugins.go:161] Loaded 11 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,CertificateSubjectRestriction,ValidatingAdmissionWebhook,ResourceQuota.
W0311 18:31:43.365909       1 genericapiserver.go:538] Skipping API apiregistration.k8s.io/v1beta1 because it has no resources.
I0311 18:31:44.416266       1 dynamic_cafile_content.go:156] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0311 18:31:44.416344       1 dynamic_serving_content.go:131] "Starting controller" name="serving-cert::/var/lib/minikube/certs/apiserver.crt::/var/lib/minikube/certs/apiserver.key"
I0311 18:31:44.416414       1 dynamic_cafile_content.go:156] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0311 18:31:44.416542       1 secure_serving.go:266] Serving securely on [::]:8443
I0311 18:31:44.416627       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0311 18:31:44.416769       1 autoregister_controller.go:141] Starting autoregister controller
I0311 18:31:44.416793       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0311 18:31:44.417082       1 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
I0311 18:31:44.417100       1 shared_informer.go:240] Waiting for caches to sync for cluster_authentication_trust_controller
I0311 18:31:44.419374       1 customresource_discovery_controller.go:209] Starting DiscoveryController
I0311 18:31:44.420352       1 controller.go:83] Starting OpenAPI AggregationController
I0311 18:31:44.420696       1 apf_controller.go:317] Starting API Priority and Fairness config controller
I0311 18:31:44.420750       1 dynamic_serving_content.go:131] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I0311 18:31:44.420914       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I0311 18:31:44.420951       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I0311 18:31:44.444669       1 available_controller.go:491] Starting AvailableConditionController
I0311 18:31:44.445247       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I0311 18:31:44.448069       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I0311 18:31:44.448391       1 shared_informer.go:240] Waiting for caches to sync for crd-autoregister
I0311 18:31:44.448756       1 dynamic_cafile_content.go:156] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0311 18:31:44.451762       1 dynamic_cafile_content.go:156] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0311 18:31:44.472390       1 controller.go:85] Starting OpenAPI controller
I0311 18:31:44.472479       1 naming_controller.go:291] Starting NamingConditionController
I0311 18:31:44.472543       1 establishing_controller.go:76] Starting EstablishingController
I0311 18:31:44.472595       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I0311 18:31:44.472660       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I0311 18:31:44.472770       1 crd_finalizer.go:266] Starting CRDFinalizer
I0311 18:31:44.542839       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0311 18:31:44.544042       1 cache.go:39] Caches are synced for autoregister controller
I0311 18:31:44.544243       1 shared_informer.go:247] Caches are synced for cluster_authentication_trust_controller 
I0311 18:31:44.549009       1 shared_informer.go:247] Caches are synced for crd-autoregister 
I0311 18:31:44.568638       1 controller.go:611] quota admission added evaluator for: namespaces
I0311 18:31:44.646725       1 apf_controller.go:322] Running API Priority and Fairness config worker
I0311 18:31:44.647837       1 cache.go:39] Caches are synced for AvailableConditionController controller
I0311 18:31:44.648227       1 shared_informer.go:247] Caches are synced for node_authorizer 
I0311 18:31:45.417504       1 controller.go:132] OpenAPI AggregationController: action for item : Nothing (removed from the queue).
I0311 18:31:45.417631       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
I0311 18:31:45.430201       1 storage_scheduling.go:93] created PriorityClass system-node-critical with value 2000001000
I0311 18:31:45.438149       1 storage_scheduling.go:93] created PriorityClass system-cluster-critical with value 2000000000
I0311 18:31:45.438193       1 storage_scheduling.go:109] all system priority classes are created successfully or already exist.
I0311 18:31:46.481230       1 controller.go:611] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I0311 18:31:46.602428       1 controller.go:611] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I0311 18:31:46.796972       1 alloc.go:329] "allocated clusterIPs" service="default/kubernetes" clusterIPs=map[IPv4:10.96.0.1]
W0311 18:31:46.807613       1 lease.go:233] Resetting endpoints for master service "kubernetes" to [192.168.49.2]
I0311 18:31:46.809975       1 controller.go:611] quota admission added evaluator for: endpoints
I0311 18:31:46.819524       1 controller.go:611] quota admission added evaluator for: endpointslices.discovery.k8s.io
I0311 18:31:47.681052       1 controller.go:611] quota admission added evaluator for: serviceaccounts
I0311 18:31:48.280529       1 controller.go:611] quota admission added evaluator for: deployments.apps
I0311 18:31:48.345646       1 alloc.go:329] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs=map[IPv4:10.96.0.10]
I0311 18:31:48.371656       1 controller.go:611] quota admission added evaluator for: daemonsets.apps
I0311 18:31:48.889583       1 controller.go:611] quota admission added evaluator for: leases.coordination.k8s.io
I0311 18:32:01.287842       1 controller.go:611] quota admission added evaluator for: replicasets.apps
I0311 18:32:01.439181       1 controller.go:611] quota admission added evaluator for: controllerrevisions.apps
I0311 18:32:02.557411       1 controller.go:611] quota admission added evaluator for: events.events.k8s.io

* 
* ==> kube-controller-manager [acb3d74309a1] <==
* I0311 18:32:00.282604       1 pv_controller_base.go:310] Starting persistent volume controller
I0311 18:32:00.282666       1 shared_informer.go:240] Waiting for caches to sync for persistent volume
I0311 18:32:00.433418       1 controllermanager.go:605] Started "attachdetach"
I0311 18:32:00.433817       1 attach_detach_controller.go:328] Starting attach detach controller
I0311 18:32:00.433932       1 shared_informer.go:240] Waiting for caches to sync for attach detach
I0311 18:32:00.442570       1 shared_informer.go:240] Waiting for caches to sync for resource quota
W0311 18:32:00.453127       1 actual_state_of_world.go:534] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="minikube" does not exist
I0311 18:32:00.456829       1 shared_informer.go:247] Caches are synced for PV protection 
I0311 18:32:00.474124       1 shared_informer.go:247] Caches are synced for crt configmap 
I0311 18:32:00.542801       1 shared_informer.go:247] Caches are synced for namespace 
I0311 18:32:00.542824       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-kubelet-serving 
I0311 18:32:00.542978       1 shared_informer.go:247] Caches are synced for certificate-csrapproving 
I0311 18:32:00.543968       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-kube-apiserver-client 
I0311 18:32:00.544122       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-legacy-unknown 
I0311 18:32:00.545104       1 shared_informer.go:247] Caches are synced for bootstrap_signer 
I0311 18:32:00.545764       1 shared_informer.go:247] Caches are synced for certificate-csrsigning-kubelet-client 
I0311 18:32:00.545821       1 shared_informer.go:247] Caches are synced for service account 
I0311 18:32:00.545127       1 shared_informer.go:247] Caches are synced for node 
I0311 18:32:00.546384       1 range_allocator.go:173] Starting range CIDR allocator
I0311 18:32:00.546411       1 shared_informer.go:240] Waiting for caches to sync for cidrallocator
I0311 18:32:00.546434       1 shared_informer.go:247] Caches are synced for cidrallocator 
I0311 18:32:00.547139       1 shared_informer.go:247] Caches are synced for TTL 
I0311 18:32:00.555462       1 shared_informer.go:247] Caches are synced for ClusterRoleAggregator 
I0311 18:32:00.557883       1 shared_informer.go:240] Waiting for caches to sync for garbage collector
I0311 18:32:00.562652       1 range_allocator.go:374] Set node minikube PodCIDR to [10.244.0.0/24]
I0311 18:32:00.634593       1 shared_informer.go:247] Caches are synced for TTL after finished 
I0311 18:32:00.642545       1 shared_informer.go:247] Caches are synced for expand 
I0311 18:32:00.642846       1 shared_informer.go:247] Caches are synced for endpoint_slice_mirroring 
I0311 18:32:00.683862       1 shared_informer.go:247] Caches are synced for cronjob 
I0311 18:32:00.697746       1 shared_informer.go:247] Caches are synced for ephemeral 
I0311 18:32:00.708986       1 shared_informer.go:247] Caches are synced for GC 
I0311 18:32:00.727926       1 shared_informer.go:247] Caches are synced for stateful set 
I0311 18:32:00.733010       1 shared_informer.go:247] Caches are synced for disruption 
I0311 18:32:00.733156       1 disruption.go:371] Sending events to api server.
I0311 18:32:00.734275       1 shared_informer.go:247] Caches are synced for attach detach 
I0311 18:32:00.736708       1 shared_informer.go:247] Caches are synced for deployment 
I0311 18:32:00.743395       1 shared_informer.go:247] Caches are synced for resource quota 
I0311 18:32:00.758495       1 shared_informer.go:247] Caches are synced for endpoint 
I0311 18:32:00.758843       1 shared_informer.go:247] Caches are synced for resource quota 
I0311 18:32:00.765792       1 shared_informer.go:247] Caches are synced for ReplicaSet 
I0311 18:32:00.769476       1 shared_informer.go:247] Caches are synced for endpoint_slice 
I0311 18:32:00.776393       1 shared_informer.go:247] Caches are synced for ReplicationController 
I0311 18:32:00.783475       1 shared_informer.go:247] Caches are synced for persistent volume 
I0311 18:32:00.783911       1 shared_informer.go:247] Caches are synced for job 
I0311 18:32:00.785271       1 shared_informer.go:247] Caches are synced for PVC protection 
I0311 18:32:00.785354       1 shared_informer.go:247] Caches are synced for HPA 
I0311 18:32:00.786827       1 shared_informer.go:247] Caches are synced for taint 
I0311 18:32:00.786939       1 node_lifecycle_controller.go:1397] Initializing eviction metric for zone: 
W0311 18:32:00.787005       1 node_lifecycle_controller.go:1012] Missing timestamp for Node minikube. Assuming now as a timestamp.
I0311 18:32:00.787113       1 node_lifecycle_controller.go:1213] Controller detected that zone  is now in state Normal.
I0311 18:32:00.787471       1 taint_manager.go:187] "Starting NoExecuteTaintManager"
I0311 18:32:00.787798       1 event.go:294] "Event occurred" object="minikube" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I0311 18:32:00.788211       1 shared_informer.go:247] Caches are synced for daemon sets 
I0311 18:32:01.159116       1 shared_informer.go:247] Caches are synced for garbage collector 
I0311 18:32:01.201769       1 shared_informer.go:247] Caches are synced for garbage collector 
I0311 18:32:01.201827       1 garbagecollector.go:155] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
I0311 18:32:01.291243       1 event.go:294] "Event occurred" object="kube-system/coredns" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-64897985d to 2"
I0311 18:32:01.448701       1 event.go:294] "Event occurred" object="kube-system/kube-proxy" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-nnr47"
I0311 18:32:01.543462       1 event.go:294] "Event occurred" object="kube-system/coredns-64897985d" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-64897985d-cm25d"
I0311 18:32:01.550965       1 event.go:294] "Event occurred" object="kube-system/coredns-64897985d" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-64897985d-hbkln"

* 
* ==> kube-proxy [5e7f097ddd9d] <==
* I0311 18:32:02.464921       1 node.go:163] Successfully retrieved node IP: 192.168.49.2
I0311 18:32:02.464991       1 server_others.go:138] "Detected node IP" address="192.168.49.2"
I0311 18:32:02.465022       1 server_others.go:561] "Unknown proxy mode, assuming iptables proxy" proxyMode=""
I0311 18:32:02.552072       1 server_others.go:206] "Using iptables Proxier"
I0311 18:32:02.552195       1 server_others.go:213] "kube-proxy running in dual-stack mode" ipFamily=IPv4
I0311 18:32:02.552225       1 server_others.go:214] "Creating dualStackProxier for iptables"
I0311 18:32:02.552254       1 server_others.go:491] "Detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, , defaulting to no-op detect-local for IPv6"
I0311 18:32:02.553101       1 server.go:656] "Version info" version="v1.23.1"
I0311 18:32:02.554213       1 config.go:317] "Starting service config controller"
I0311 18:32:02.554257       1 shared_informer.go:240] Waiting for caches to sync for service config
I0311 18:32:02.554757       1 config.go:226] "Starting endpoint slice config controller"
I0311 18:32:02.554811       1 shared_informer.go:240] Waiting for caches to sync for endpoint slice config
I0311 18:32:02.655392       1 shared_informer.go:247] Caches are synced for service config 
I0311 18:32:02.655499       1 shared_informer.go:247] Caches are synced for endpoint slice config 

* 
* ==> kube-scheduler [f0562a22e7dc] <==
* W0311 18:31:44.555251       1 authentication.go:346] Continuing without authentication configuration. This may treat all requests as anonymous.
W0311 18:31:44.557892       1 authentication.go:347] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0311 18:31:44.652240       1 server.go:139] "Starting Kubernetes Scheduler" version="v1.23.1"
I0311 18:31:44.656243       1 secure_serving.go:200] Serving securely on 127.0.0.1:10259
I0311 18:31:44.659404       1 configmap_cafile_content.go:201] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0311 18:31:44.659592       1 shared_informer.go:240] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0311 18:31:44.659818       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
W0311 18:31:44.663989       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0311 18:31:44.664144       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0311 18:31:44.664383       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0311 18:31:44.668563       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0311 18:31:44.668981       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0311 18:31:44.669050       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0311 18:31:44.669215       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0311 18:31:44.669345       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0311 18:31:44.670203       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0311 18:31:44.677053       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0311 18:31:44.670348       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1beta1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0311 18:31:44.678082       1 reflector.go:324] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:205: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0311 18:31:44.678162       1 reflector.go:138] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:205: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0311 18:31:44.677774       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1beta1.CSIStorageCapacity: failed to list *v1beta1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0311 18:31:44.678578       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0311 18:31:44.678723       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0311 18:31:44.678952       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0311 18:31:44.679163       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0311 18:31:44.679487       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0311 18:31:44.679610       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0311 18:31:44.679678       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0311 18:31:44.679644       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0311 18:31:44.679930       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0311 18:31:44.680008       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0311 18:31:44.670510       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0311 18:31:44.680185       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0311 18:31:44.676703       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0311 18:31:44.680255       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W0311 18:31:44.744283       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0311 18:31:44.745230       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0311 18:31:45.594000       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0311 18:31:45.594043       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0311 18:31:45.612471       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0311 18:31:45.612529       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0311 18:31:45.645716       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0311 18:31:45.645830       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0311 18:31:45.696953       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0311 18:31:45.697028       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0311 18:31:45.815297       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0311 18:31:45.815480       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0311 18:31:45.832945       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0311 18:31:45.833051       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0311 18:31:45.872700       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0311 18:31:45.872762       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0311 18:31:45.946272       1 reflector.go:324] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:205: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0311 18:31:45.946479       1 reflector.go:138] k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:205: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0311 18:31:45.946487       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0311 18:31:45.946773       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0311 18:31:45.968675       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0311 18:31:45.968736       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0311 18:31:45.995852       1 reflector.go:324] k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0311 18:31:45.995910       1 reflector.go:138] k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
I0311 18:31:48.960449       1 shared_informer.go:247] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file 

* 
* ==> kubelet <==
* -- Logs begin at Fri 2022-03-11 18:28:05 UTC, end at Fri 2022-03-11 18:32:13 UTC. --
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.057013    4977 kubelet_node_status.go:108] "Node was previously registered" node="minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.057139    4977 kubelet_node_status.go:73] "Successfully registered node" node="minikube"
Mar 11 18:31:49 minikube kubelet[4977]: E0311 18:31:49.144945    4977 kubelet.go:2001] "Skipping pod synchronization" err="container runtime status check may not have completed yet"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.147915    4977 setters.go:578] "Node became not ready" node="minikube" condition={Type:Ready Status:False LastHeartbeatTime:2022-03-11 18:31:49.1478083 +0000 UTC m=+0.900033701 LastTransitionTime:2022-03-11 18:31:49.1478083 +0000 UTC m=+0.900033701 Reason:KubeletNotReady Message:container runtime status check may not have completed yet}
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.340995    4977 cpu_manager.go:213] "Starting CPU manager" policy="none"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.341053    4977 cpu_manager.go:214] "Reconciling" reconcilePeriod="10s"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.341086    4977 state_mem.go:36] "Initialized new in-memory state store"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.341256    4977 state_mem.go:88] "Updated default CPUSet" cpuSet=""
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.341345    4977 state_mem.go:96] "Updated CPUSet assignments" assignments=map[]
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.341367    4977 policy_none.go:49] "None policy: Start"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.344938    4977 memory_manager.go:168] "Starting memorymanager" policy="None"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.344968    4977 state_mem.go:35] "Initializing new in-memory state store"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.345087    4977 state_mem.go:75] "Updated machine memory state"
Mar 11 18:31:49 minikube kubelet[4977]: E0311 18:31:49.345129    4977 kubelet.go:2001] "Skipping pod synchronization" err="container runtime status check may not have completed yet"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.346484    4977 manager.go:610] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.346751    4977 plugin_manager.go:114] "Starting Kubelet Plugin Manager"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.747122    4977 topology_manager.go:200] "Topology Admit Handler"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.747501    4977 topology_manager.go:200] "Topology Admit Handler"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.747663    4977 topology_manager.go:200] "Topology Admit Handler"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.747790    4977 topology_manager.go:200] "Topology Admit Handler"
Mar 11 18:31:49 minikube kubelet[4977]: E0311 18:31:49.764400    4977 kubelet.go:1711] "Failed creating a mirror pod for" err="pods \"kube-scheduler-minikube\" already exists" pod="kube-system/kube-scheduler-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: E0311 18:31:49.764608    4977 kubelet.go:1711] "Failed creating a mirror pod for" err="pods \"etcd-minikube\" already exists" pod="kube-system/etcd-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: E0311 18:31:49.765484    4977 kubelet.go:1711] "Failed creating a mirror pod for" err="pods \"kube-apiserver-minikube\" already exists" pod="kube-system/kube-apiserver-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.783805    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/b8bdc344ff0000e961009344b94de59c-kubeconfig\") pod \"kube-scheduler-minikube\" (UID: \"b8bdc344ff0000e961009344b94de59c\") " pod="kube-system/kube-scheduler-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.783954    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/96be69ce9ff7dc0acff6fda2873a009a-ca-certs\") pod \"kube-apiserver-minikube\" (UID: \"96be69ce9ff7dc0acff6fda2873a009a\") " pod="kube-system/kube-apiserver-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.784057    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/96be69ce9ff7dc0acff6fda2873a009a-usr-share-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"96be69ce9ff7dc0acff6fda2873a009a\") " pod="kube-system/kube-apiserver-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.784123    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/96be69ce9ff7dc0acff6fda2873a009a-k8s-certs\") pod \"kube-apiserver-minikube\" (UID: \"96be69ce9ff7dc0acff6fda2873a009a\") " pod="kube-system/kube-apiserver-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.784177    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/96be69ce9ff7dc0acff6fda2873a009a-usr-local-share-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"96be69ce9ff7dc0acff6fda2873a009a\") " pod="kube-system/kube-apiserver-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.784228    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/3db91997554714e5ece3296773cf98a5-k8s-certs\") pod \"kube-controller-manager-minikube\" (UID: \"3db91997554714e5ece3296773cf98a5\") " pod="kube-system/kube-controller-manager-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.784394    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/3db91997554714e5ece3296773cf98a5-usr-share-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"3db91997554714e5ece3296773cf98a5\") " pod="kube-system/kube-controller-manager-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.784450    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/3db91997554714e5ece3296773cf98a5-kubeconfig\") pod \"kube-controller-manager-minikube\" (UID: \"3db91997554714e5ece3296773cf98a5\") " pod="kube-system/kube-controller-manager-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.784507    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/9d3d310935e5fabe942511eec3e2cd0c-etcd-certs\") pod \"etcd-minikube\" (UID: \"9d3d310935e5fabe942511eec3e2cd0c\") " pod="kube-system/etcd-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.784555    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/9d3d310935e5fabe942511eec3e2cd0c-etcd-data\") pod \"etcd-minikube\" (UID: \"9d3d310935e5fabe942511eec3e2cd0c\") " pod="kube-system/etcd-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.784604    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/96be69ce9ff7dc0acff6fda2873a009a-etc-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"96be69ce9ff7dc0acff6fda2873a009a\") " pod="kube-system/kube-apiserver-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.784661    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/3db91997554714e5ece3296773cf98a5-ca-certs\") pod \"kube-controller-manager-minikube\" (UID: \"3db91997554714e5ece3296773cf98a5\") " pod="kube-system/kube-controller-manager-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.784718    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/3db91997554714e5ece3296773cf98a5-etc-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"3db91997554714e5ece3296773cf98a5\") " pod="kube-system/kube-controller-manager-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.784777    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/3db91997554714e5ece3296773cf98a5-flexvolume-dir\") pod \"kube-controller-manager-minikube\" (UID: \"3db91997554714e5ece3296773cf98a5\") " pod="kube-system/kube-controller-manager-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.784825    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/3db91997554714e5ece3296773cf98a5-usr-local-share-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"3db91997554714e5ece3296773cf98a5\") " pod="kube-system/kube-controller-manager-minikube"
Mar 11 18:31:49 minikube kubelet[4977]: I0311 18:31:49.807023    4977 apiserver.go:52] "Watching apiserver"
Mar 11 18:31:50 minikube kubelet[4977]: I0311 18:31:50.087550    4977 reconciler.go:157] "Reconciler: start to sync state"
Mar 11 18:32:00 minikube kubelet[4977]: I0311 18:32:00.658249    4977 kuberuntime_manager.go:1098] "Updating runtime config through cri with podcidr" CIDR="10.244.0.0/24"
Mar 11 18:32:00 minikube kubelet[4977]: I0311 18:32:00.658974    4977 docker_service.go:364] "Docker cri received runtime config" runtimeConfig="&RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:10.244.0.0/24,},}"
Mar 11 18:32:00 minikube kubelet[4977]: I0311 18:32:00.659170    4977 kubelet_network.go:76] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.0.0/24"
Mar 11 18:32:01 minikube kubelet[4977]: I0311 18:32:01.456056    4977 topology_manager.go:200] "Topology Admit Handler"
Mar 11 18:32:01 minikube kubelet[4977]: I0311 18:32:01.480925    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/af859208-d854-4f71-b92e-e5d64072769e-kube-proxy\") pod \"kube-proxy-nnr47\" (UID: \"af859208-d854-4f71-b92e-e5d64072769e\") " pod="kube-system/kube-proxy-nnr47"
Mar 11 18:32:01 minikube kubelet[4977]: I0311 18:32:01.481009    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/af859208-d854-4f71-b92e-e5d64072769e-xtables-lock\") pod \"kube-proxy-nnr47\" (UID: \"af859208-d854-4f71-b92e-e5d64072769e\") " pod="kube-system/kube-proxy-nnr47"
Mar 11 18:32:01 minikube kubelet[4977]: I0311 18:32:01.481063    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/af859208-d854-4f71-b92e-e5d64072769e-lib-modules\") pod \"kube-proxy-nnr47\" (UID: \"af859208-d854-4f71-b92e-e5d64072769e\") " pod="kube-system/kube-proxy-nnr47"
Mar 11 18:32:01 minikube kubelet[4977]: I0311 18:32:01.481113    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-94pwg\" (UniqueName: \"kubernetes.io/projected/af859208-d854-4f71-b92e-e5d64072769e-kube-api-access-94pwg\") pod \"kube-proxy-nnr47\" (UID: \"af859208-d854-4f71-b92e-e5d64072769e\") " pod="kube-system/kube-proxy-nnr47"
Mar 11 18:32:01 minikube kubelet[4977]: I0311 18:32:01.560827    4977 topology_manager.go:200] "Topology Admit Handler"
Mar 11 18:32:01 minikube kubelet[4977]: I0311 18:32:01.580342    4977 topology_manager.go:200] "Topology Admit Handler"
Mar 11 18:32:01 minikube kubelet[4977]: I0311 18:32:01.743138    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-4dnxf\" (UniqueName: \"kubernetes.io/projected/6015b8a9-681f-4044-889d-fdc7b00cf4cc-kube-api-access-4dnxf\") pod \"coredns-64897985d-hbkln\" (UID: \"6015b8a9-681f-4044-889d-fdc7b00cf4cc\") " pod="kube-system/coredns-64897985d-hbkln"
Mar 11 18:32:01 minikube kubelet[4977]: I0311 18:32:01.743649    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-9shwn\" (UniqueName: \"kubernetes.io/projected/dde2a93a-6182-4055-adbd-1cb5a7ad4fbf-kube-api-access-9shwn\") pod \"coredns-64897985d-cm25d\" (UID: \"dde2a93a-6182-4055-adbd-1cb5a7ad4fbf\") " pod="kube-system/coredns-64897985d-cm25d"
Mar 11 18:32:01 minikube kubelet[4977]: I0311 18:32:01.743741    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/dde2a93a-6182-4055-adbd-1cb5a7ad4fbf-config-volume\") pod \"coredns-64897985d-cm25d\" (UID: \"dde2a93a-6182-4055-adbd-1cb5a7ad4fbf\") " pod="kube-system/coredns-64897985d-cm25d"
Mar 11 18:32:01 minikube kubelet[4977]: I0311 18:32:01.743998    4977 reconciler.go:216] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/6015b8a9-681f-4044-889d-fdc7b00cf4cc-config-volume\") pod \"coredns-64897985d-hbkln\" (UID: \"6015b8a9-681f-4044-889d-fdc7b00cf4cc\") " pod="kube-system/coredns-64897985d-hbkln"
Mar 11 18:32:02 minikube kubelet[4977]: I0311 18:32:02.658166    4977 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="f72c38b9191e438e4c1de54ef5e815d2a7301a51f98748848c1474b13fc181d7"
Mar 11 18:32:02 minikube kubelet[4977]: I0311 18:32:02.661686    4977 docker_sandbox.go:402] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for kube-system/coredns-64897985d-cm25d through plugin: invalid network status for"
Mar 11 18:32:02 minikube kubelet[4977]: I0311 18:32:02.787655    4977 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="69b427ea64e4c0c84cf5d91b4a491a261da6d0ef9770d21c87048e98e1262b9d"
Mar 11 18:32:02 minikube kubelet[4977]: I0311 18:32:02.787755    4977 docker_sandbox.go:402] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for kube-system/coredns-64897985d-hbkln through plugin: invalid network status for"
Mar 11 18:32:03 minikube kubelet[4977]: I0311 18:32:03.798087    4977 docker_sandbox.go:402] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for kube-system/coredns-64897985d-cm25d through plugin: invalid network status for"
Mar 11 18:32:03 minikube kubelet[4977]: I0311 18:32:03.817124    4977 docker_sandbox.go:402] "Failed to read pod IP from plugin/docker" err="Couldn't find network status for kube-system/coredns-64897985d-hbkln through plugin: invalid network status for"

